{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVKJbAv69q4TXe1ZaW7Wi9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SSRavipati/LLM-course/blob/main/chapter_2/%20models_and_tokenizers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vg9o2MxOnl7E"
      },
      "outputs": [],
      "source": [
        "import transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AutoModel class is actually a clever wrapper, this can find the appropriate model architecture based on the provided check point and then istantiates the model with the architecture\n",
        "If you know the model name you can use the class that defines the model architecture"
      ],
      "metadata": {
        "id": "_3lW5Hjmn6u3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Transformer"
      ],
      "metadata": {
        "id": "-iNzcAydobYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel, BertConfig\n",
        "#the config has the attributes to build the model\n",
        "config = BertConfig()\n",
        "model = BertModel(config)\n",
        "# model is randomly initialised"
      ],
      "metadata": {
        "id": "VDzgb4fTnsWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above case model is randomly initialised, it needs to be pretrained for which it needs the information of the weights"
      ],
      "metadata": {
        "id": "jmsPEdIopBJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertModel.from_pretrained('bert-base-cased')\n",
        "# this check point is trained, we are doing this using from_pretrained() method, we do not need the config here"
      ],
      "metadata": {
        "id": "PU5Se2EWpwjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could replace BertModel with AutoModel as it produces a checkpoint agnostic code"
      ],
      "metadata": {
        "id": "m7J3MxgWqMtN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the model"
      ],
      "metadata": {
        "id": "qHRvVv7jrshO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"dir_on_computer\")"
      ],
      "metadata": {
        "id": "cy-pA8btrr_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using transformer for inference"
      ],
      "metadata": {
        "id": "--U-xvRnrz2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = [\"Hello!\", \"Cool.\", \"Nice!\"]"
      ],
      "metadata": {
        "id": "eNQlzQ0Rry1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "id": "8nmbSD5Uslca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_sequences = tokenizer(sequences, padding = True, truncation = True, return_tensors = \"pt\")\n",
        "print(encoded_sequences)"
      ],
      "metadata": {
        "id": "nhPsXIUIrypq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "model_inputs = encoded_sequences['input_ids']"
      ],
      "metadata": {
        "id": "6RwqSbf-sXek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(model_inputs)"
      ],
      "metadata": {
        "id": "uQh7mUFAth4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output)"
      ],
      "metadata": {
        "id": "Rd5TJw1jt71k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TOKENIZER**"
      ],
      "metadata": {
        "id": "Ln7tVfuO0-dZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   WORD BASED\n",
        "Splits the input such that each word is a token\n",
        "Huge vocabulary, could result in many unknown tokens\n",
        "\n",
        "2.   CHARACTER BASED\n",
        "each character is a token\n",
        "vocabulary is limited, but the sequences are huge, and the meaning is lost as characters rarely have meaning\n",
        "3.   SUBWORD TOKENIZER\n",
        "is a mix of earlier ones\n",
        "known words are left as is and unknown words or complex words are spint into parts\n",
        "\n",
        "most of the models use some form of subword tokenizer\n",
        "\n"
      ],
      "metadata": {
        "id": "XCzIVSLf1HJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "id": "L4kmUA6Gt-aC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\"makikirikiri\")\n",
        "print(inputs)"
      ],
      "metadata": {
        "id": "lzY_QMH01_X9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization"
      ],
      "metadata": {
        "id": "jtuDniJ62xT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "sequence = \"When I get older and so on\"\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "DIza_AM72k_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding\n"
      ],
      "metadata": {
        "id": "u8xmQr-s3b_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(ids)"
      ],
      "metadata": {
        "id": "o_2HNhFZ3J19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoding"
      ],
      "metadata": {
        "id": "DBvRYWfV3abY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_string = tokenizer.decode(ids)\n",
        "print(decoded_string)"
      ],
      "metadata": {
        "id": "S4qTKpAv3Wjq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}