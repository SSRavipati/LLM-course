{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAUoFq6GMX+0HHFr7AeVqb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SSRavipati/LLM-course/blob/main/chapter_2/Full_training_loop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers evaluate torch"
      ],
      "metadata": {
        "id": "wHXds5B2oMLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full training with out API"
      ],
      "metadata": {
        "id": "oemA5fJL2XBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade datasets fsspec"
      ],
      "metadata": {
        "id": "Q9d39kq-oI6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nylbLXtn9kg"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "\n",
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
        "\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare for training**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "We will use dataloaders to iterate over batches.\n",
        "\n",
        "Before we can define those dataloaders, we need to apply a bit of postprocessing to our tokenized_datasets, to take care of some things that the Trainer did for us automatically.\n",
        "\n",
        "Specifically, we need to:\n",
        "\n",
        "Remove the columns corresponding to values the model does not expect (like the sentence1 and sentence2 columns).\n",
        "\n",
        "Rename the column label to labels (because the model expects the argument to be named labels).\n",
        "\n",
        "Set the format of the datasets so they return PyTorch tensors instead of lists.\n",
        "Our tokenized_datasets has one method for each of those steps:"
      ],
      "metadata": {
        "id": "gAtV24Rv2liS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = tokenized_datasets.remove_columns([\"sentence1\", \"sentence2\", \"idx\"])\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "tokenized_datasets[\"train\"].column_names"
      ],
      "metadata": {
        "id": "85v8VonS28bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define dataloaders"
      ],
      "metadata": {
        "id": "98_STl0s3G3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"validation\"], batch_size=8, collate_fn=data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "ReFER_yx3DqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "to inspect the batch"
      ],
      "metadata": {
        "id": "H8A63EnR3Rvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dataloader:\n",
        "    break\n",
        "{k: v.shape for k, v in batch.items()}"
      ],
      "metadata": {
        "id": "J_OqXAJa3De7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "instantiating the model"
      ],
      "metadata": {
        "id": "lmtwpRJl4juu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
      ],
      "metadata": {
        "id": "pSeZqCm53DUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**batch)\n",
        "print(outputs.loss, outputs.logits.shape)"
      ],
      "metadata": {
        "id": "HpeWrQMR4pgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training loop is missing two things: an optimizer and a learning rate scheduler."
      ],
      "metadata": {
        "id": "GBX632Bo47zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "y--0kxjM4pcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " learning rate scheduler used by default is just a linear decay from the maximum value (5e-5) to 0."
      ],
      "metadata": {
        "id": "Ktb7ajhz5IXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_scheduler\n",
        "\n",
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "print(num_training_steps)"
      ],
      "metadata": {
        "id": "qoLB_BHd4pZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "device"
      ],
      "metadata": {
        "id": "_IDqKDto4pWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device(type='cuda')"
      ],
      "metadata": {
        "id": "5YA5t3Dd4pPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tqdm library used to show the progress bar"
      ],
      "metadata": {
        "id": "l2SV4opP5XgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)"
      ],
      "metadata": {
        "id": "j_2HfQeF5UqF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}